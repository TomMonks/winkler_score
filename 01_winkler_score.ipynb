{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winkler score\n",
    "\n",
    "An alternative way to assess prediction interval coverage for a specific time series is using the Winkler score.  This notebook contains code for the Winkler score as a measure of forecast accuracy of a prediction interval\n",
    "\n",
    "The winkler score is defined as\n",
    "\n",
    "$$W_{\\alpha,t} = \\begin{cases}\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t}) + \\frac{2}{\\alpha} (\\ell_{\\alpha,t} - y_t) & \\text{if } y_t < \\ell_{\\alpha,t} \\\\\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t})   & \\text{if }  \\ell_{\\alpha,t} \\le y_t \\le u_{\\alpha,t} \\\\\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t}) + \\frac{2}{\\alpha} (y_t - u_{\\alpha,t}) & \\text{if } y_t > u_{\\alpha,t}.\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  \n",
    "Where \n",
    "\n",
    "* $u_{\\alpha, t}$ is the upper prediction interval value for $\\alpha$ and horizon $t$\n",
    "* $l_{\\alpha, t}$ is the lower prediction interval value for $\\alpha$ and horizon $t$\n",
    "* $y_t$ is the ground truth observation at horizon $t$\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "* A Winkler score is the width of the interval plus a penality proportional to the deviation (above or below the interval) and 2/$\\alpha$\n",
    "* Smaller winkler scores are better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "\n",
    "from forecast_tools.baseline import Naive1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winkler score implementation\n",
    "\n",
    "The above formula is easily implemented as a simple if-else statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winkler_score(l_interval, u_interval, y_t, alpha):\n",
    "    '''\n",
    "    Calculates the Winkler score for an observation in \n",
    "    an prediction interval.\n",
    "    \n",
    "    Winkler scores penalise intervals that do not capture the \n",
    "    observation proportional to 2/alpha\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    l_interval: float\n",
    "        Lower prediction interval\n",
    "        \n",
    "    u_interval: float\n",
    "        Upper prediction interval\n",
    "        \n",
    "    y_t: float\n",
    "        Observed ground truth value\n",
    "        \n",
    "    alpha: float\n",
    "        The prediction interval alpha.  For an 80% pred intervals alpha=0.2\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    float\n",
    "    \n",
    "    Example usage:\n",
    "    --------------\n",
    "    ```python\n",
    "    >> alpha = 0.2\n",
    "    >> interval = [744.54, 773.22]\n",
    "    >> y_t = 741.84\n",
    "    >> ws = winkler_score(interval, y_t, alpha)\n",
    "    >> print(round(ws, 2))\n",
    "    \n",
    "    56.68\n",
    "    ```\n",
    "    '''\n",
    "    score = u_interval - l_interval\n",
    "    if y_t < l_interval:\n",
    "        score += ((2/alpha) * (l_interval - y_t))\n",
    "    elif y_t > u_interval:\n",
    "        score += ((2/alpha) * (y_t - u_interval))\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_winkler_score(intervals, observations, alpha):\n",
    "    '''\n",
    "    Returns the mean winkler score across a set of \n",
    "    intervals and also a numpy.ndarray of individual winkler scores\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    intervals: array-like\n",
    "        array of prediction intervals\n",
    "        \n",
    "    observations: array-like\n",
    "        array of ground truth observations\n",
    "        \n",
    "    alpha: float\n",
    "        The prediction interval alpha.  For an 80% pred intervals alpha=0.2\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    float, numpy.ndarray\n",
    "    \n",
    "    '''\n",
    "    if isinstance(observations, pd.DataFrame):\n",
    "        observations = observations.to_numpy()\n",
    "    scores = [winkler_score(l[0], l[1], y_t, alpha) for l, y_t in zip(intervals, observations)]\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean(), scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_winker_score(interval, y_t, alpha, expected):\n",
    "    '''\n",
    "    Test the winkler score works as expected.\n",
    "    '''\n",
    "    ws = winkler_score(interval[0], interval[1], y_t, alpha)\n",
    "    return expected == pytest.approx(ws, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example data from Forecasting principals and practice\n",
    "alpha = 0.2 # i.e. a 80% prediction interval\n",
    "interval = [744.54, 773.22]\n",
    "y_t = 741.84\n",
    "expected = 56.68\n",
    "test_winker_score(interval, y_t, alpha, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple intervals example\n",
    "\n",
    "Using the outpatient appointments dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "        + 'hpdm097-datasets/master/out_appoints_mth.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "appoints = pd.read_csv(url, index_col='date', parse_dates=True, dayfirst=True)\n",
    "appoints.index.freq = 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = appoints[:-6]\n",
    "test = appoints[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47563])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Naive1()\n",
    "preds, intervals = model.fit_predict(train, 6, return_predict_int=True, alpha=[0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45713.46342943, 71484.53657057],\n",
       "       [40376.09942344, 76821.90057656],\n",
       "       [36280.59597698, 80917.40402302],\n",
       "       [32827.92685885, 84370.07314115],\n",
       "       [29786.06430164, 87411.93569836],\n",
       "       [27036.01034012, 90161.98965988]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_score, scores = mean_winkler_score(intervals[0], test, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46524.61322318127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25771.07314115, 36445.80115312, 44636.80804604, 51542.1462823 ,\n",
       "       57625.87139673, 63125.97931976])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
